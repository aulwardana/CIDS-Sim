{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8728323",
   "metadata": {},
   "source": [
    "# CIDS-Sim with Non-IID data\n",
    "\n",
    "Federated Learning enables collaboration among multiple clients to learn from decentralized data. In the context of Collaborative Intrusion Detection Systems (CIDS), each client serves as a detector unit distributed across different networks, while the central server, responsible for aggregating the models, functions as the correlation unit. This simulator operates in a non-IID (Non-Independent and Identically Distributed) data environment, where data is distributed across clients in a heterogeneous manner. For this simulation, the CoAt_NF-UQ-NIDS-V2.parquet dataset is used, with the data split non-IID across clients. The Federated Averaging (FedAvg) algorithm is employed to aggregate the models from multiple clients.\n",
    "\n",
    "## CIDS Architecture\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"699\" alt=\"image\" src=\"https://github.com/aulwardana/CIDS-Sim/blob/main/images/arch_CIDS-Sim_Non-IID.jpg?raw=true\">\n",
    "</p>\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "This simulator will use a Coordinated Attack dataset from [here](https://data.mendeley.com/datasets/28tmfg3rzb/2).\n",
    "\n",
    "## Other Information\n",
    "\n",
    "The simulator will run binary classification, so the traffic will labeled as normal (0) or anomaly (1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b32ae",
   "metadata": {},
   "source": [
    "First, import libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.metrics import Recall, Precision\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc772518",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Load Coordinated Attack dataset. We are using \".parquet\" file for faster reading data.\n",
    "\n",
    "Use `CoAt_NF-UQ-NIDS-V2.parquet` for a dataset with the NF feature for the Non-IID scenario.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b845ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset file\n",
    "file_path = os.path.join('..', '..', 'dataset', 'CoAt_NF-UQ-NIDS-V2.parquet')\n",
    "\n",
    "# Use this to read dataset using parquet file (default)\n",
    "df = pd.read_parquet(file_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a1b29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "View the dataset information\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e956a04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a binary label, so we drop the multi-class label\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98786d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Label'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d12df-ed87-429c-b246-ec8c1b1ef170",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "View normal (0) and anomaly (1) traffic distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae32fb-5b50-4577-a6fa-d02fba071611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attack'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3dad7d-b2d0-473f-8820-95d8f13b363d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "X and y are used to represent the input features and the corresponding target labels, respectively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9092c-bcb3-4e98-ba55-07dea52806b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.drop(columns=['Attack'])\n",
    "y_df = df['Attack']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e4fdc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Scaling data to ensures that features have values in the same range\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63835f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this scaler for NF dataset\n",
    "scaler = QuantileTransformer(output_distribution='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_scl = scaler.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc08328",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This Python function, `load_data(client_id)`, is designed to load a portion of data for a specific client in a Federated Learning setting where non-IID data is distributed among different clients. That process is designed to divide a large dataset into smaller portions for different clients.\n",
    "\n",
    "Please change `fraction` variable if you want to change the data portion that will distribute to each client.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(client_id):\n",
    "    \n",
    "    # Create non-IID splits based on client_id\n",
    "    np.random.seed(client_id)\n",
    "    indices = np.arange(len(X_df_scl))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Choose a fraction of the data for this client\n",
    "    fraction = 0.02\n",
    "    client_data_size = int(fraction * len(X_df_scl))\n",
    "    client_indices = indices[:client_data_size]\n",
    "\n",
    "    X_client = X_df_scl[client_indices]\n",
    "    y_client = y_df.iloc[client_indices]\n",
    "\n",
    "    return X_client, y_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4d90a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The `create_model()` function defines a simple deep neural network model using Keras.\n",
    "You can change the **number of neurons** in each **Dense layer**.\n",
    "You can also experiment by changing the **Activation function, Loss function, and optimizer** from the deep learning model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model\n",
    "def create_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='relu', input_shape=(input_shape,)),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(5, activation='relu'),\n",
    "        layers.Dense(3, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy', Recall(), Precision()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56eab47-d3f6-41b2-914f-dca566da7123",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Calculate model size to measure the overhead in communication\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0b1fb-2e17-4763-bf30-5a4a202d7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_size(model):\n",
    "    \"\"\"Calculate the size of a model (in bytes) by summing the number of parameters.\"\"\"\n",
    "    total_params = np.sum([np.prod(weights.shape) for weights in model.get_weights()])\n",
    "    size_in_bytes = total_params * 4  # Assuming 32-bit float (4 bytes per parameter)\n",
    "    return size_in_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebd9e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The `cids_federated_training()` function implements the **training process for a Collaborative Intrusion Detection System (CIDS) using Federated Learning**. The goal is to train a global model based on the local training of models across multiple distributed nodes, without sharing raw data. \n",
    "\n",
    "This function performs federated learning for intrusion detection across `num_nodes` (clients or devices) over `num_rounds` (iterations of federated learning). You can experiment by changing `num_nodes` and `num_rounds` from this function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be28f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIDS with federated learning training process\n",
    "\n",
    "# change num_nodes and num_rounds for your simulation scenario\n",
    "\n",
    "def cids_federated_training(num_nodes=5, num_rounds=5): \n",
    "    input_shape_glob = X_df_scl.shape[1]\n",
    "    global_model = create_model(input_shape=input_shape_glob)\n",
    "    global_weights = global_model.get_weights()\n",
    "\n",
    "    global_pred_times = []\n",
    "\n",
    "    # Calculate model size (bytes per round of communication)\n",
    "    model_size = calculate_model_size(global_model)\n",
    "    print(f\"Model size: {model_size / 1e6:.2f} MB\")\n",
    "\n",
    "    communication_overhead = 0\n",
    "\n",
    "    #Global model performance evaluation\n",
    "    global_accuracies = []\n",
    "    global_precisions = []\n",
    "    global_recalls = []\n",
    "    global_f1s = []\n",
    "\n",
    "    # Variable for global training and prediction time\n",
    "    total_training_times = []\n",
    "    total_prediction_times = []\n",
    "\n",
    "    # Variable for global training CPU and Memory usage\n",
    "    cpu_usages = []\n",
    "    memory_usages = []\n",
    "\n",
    "    # Variable for global variance in performance across nodes\n",
    "    accuracy_variances = []\n",
    "    precision_variances = []\n",
    "    recall_variances = []\n",
    "    f1_variances = []\n",
    "\n",
    "    # Variable for global standard deviation of performance\n",
    "    accuracy_stds = []\n",
    "    precision_stds = []\n",
    "    recall_stds = []\n",
    "    f1_stds = []\n",
    "\n",
    "    # Initial evaluation\n",
    "    X_test, Y_test = load_data(num_nodes+1)\n",
    "\n",
    "    # Training rounds\n",
    "    for round in range(num_rounds):\n",
    "        local_weights = []\n",
    "        local_training_times = []\n",
    "        local_prediction_times = []\n",
    "\n",
    "        #Local model performance evaluation\n",
    "        local_accuracies = []\n",
    "        local_precisions = []\n",
    "        local_recalls = []\n",
    "        local_f1s = []\n",
    "\n",
    "        # Local CPU and Memory usage\n",
    "        round_cpu_usage = []\n",
    "        round_memory_usage = []\n",
    "\n",
    "        print(f\"\\n------------------------------------------------------------\\n\")\n",
    "        print(f\"Training Round {round + 1}\\n\")\n",
    "\n",
    "        for node in range(num_nodes):\n",
    "            X, Y = load_data(node)\n",
    "                    \n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "            \n",
    "            input_shape = X_train.shape[1]\n",
    "\n",
    "            model = create_model(input_shape=input_shape)\n",
    "            model.set_weights(global_weights)\n",
    "\n",
    "            # Measure CPU and memory utilization during training\n",
    "            cpu_before = psutil.cpu_percent(interval=None)\n",
    "            memory_before = psutil.virtual_memory().percent\n",
    "\n",
    "            # Measure local training time\n",
    "            start_train_time = time.time()\n",
    "            #local training time\n",
    "            model.fit(X_train, Y_train, epochs=10, batch_size=1000, verbose=0)\n",
    "            end_train_time = time.time()\n",
    "\n",
    "            cpu_after = psutil.cpu_percent(interval=None)\n",
    "            memory_after = psutil.virtual_memory().percent\n",
    "\n",
    "            local_training_time = end_train_time - start_train_time\n",
    "            local_training_times.append(local_training_time)\n",
    "\n",
    "            cpu_usage = cpu_after - cpu_before\n",
    "            memory_usage = memory_after - memory_before\n",
    "\n",
    "            print(f\"Node {node + 1}: Training Time {local_training_time:.4f} seconds\")\n",
    "            print(f\"Node {node + 1}: CPU Usage {cpu_usage:.2f}% - Memory Usage {memory_usage:.2f}%\")\n",
    "\n",
    "            # Measure local resource consumption\n",
    "            round_cpu_usage.append(cpu_usage)\n",
    "            round_memory_usage.append(memory_usage)\n",
    "\n",
    "            # Measure local prediction time\n",
    "            start_pred_time = time.time()\n",
    "            # Validation\n",
    "            loss, accuracy, precision, recall = model.evaluate(X_val, Y_val, verbose=0)\n",
    "            end_pred_time = time.time()\n",
    "\n",
    "            local_prediction_time = end_pred_time - start_pred_time\n",
    "            local_prediction_times.append(local_prediction_time)\n",
    "\n",
    "            print(f\"Node {node + 1}: Prediction Time {local_prediction_time:.4f} seconds\")\n",
    "            \n",
    "            f1_score = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "            print(f\"Node {node + 1}: Accuracy {accuracy:.4f} - Precision {precision:.4f} - Recall {recall:.4f} - F1-Score {f1_score:.4f}\\n\")\n",
    "\n",
    "            #Append local performance data\n",
    "            local_accuracies.append(accuracy)\n",
    "            local_precisions.append(precision)\n",
    "            local_recalls.append(recall)\n",
    "            local_f1s.append(f1_score)\n",
    "            \n",
    "            local_weights.append(model.get_weights())\n",
    "\n",
    "            # Communication: Server receiving weights from each node\n",
    "            communication_overhead += model_size\n",
    "\n",
    "        # Measure server aggregation time\n",
    "        start_aggregation_time = time.time()\n",
    "        # Aggregate weights\n",
    "        new_weights = [np.mean([weight[layer] for weight in local_weights], axis=0) for layer in range(len(global_weights))]\n",
    "        end_aggregation_time = time.time()\n",
    "        \n",
    "        aggregation_time = end_aggregation_time - start_aggregation_time\n",
    "        print(f\"Aggregation Time round {round + 1}: {aggregation_time:.4f} seconds\")\n",
    "        \n",
    "        global_weights = new_weights\n",
    "        global_model.set_weights(global_weights)\n",
    "\n",
    "        # Communication: Server sending updated weights to all nodes\n",
    "        communication_overhead += num_nodes * model_size\n",
    "\n",
    "        print(f\"Total communication overhead after round {round + 1}: {communication_overhead / 1e6:.2f} MB\")\n",
    "\n",
    "        # Evaluate and measure the time\n",
    "        start_glob_pred_time = time.time()\n",
    "        loss, accuracy, precision, recall = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        end_glob_pred_time = time.time()\n",
    "\n",
    "        global_pred_time = end_glob_pred_time - start_glob_pred_time\n",
    "        global_pred_times.append(global_pred_time)\n",
    "\n",
    "        print(f\"\\nGlobal Prediction Time Round {round + 1}: {global_pred_time:.4f}\")\n",
    "\n",
    "        # Evaluate global model accuracy\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "        global_accuracies.append(accuracy)\n",
    "        global_precisions.append(precision)\n",
    "        global_recalls.append(recall)\n",
    "        global_f1s.append(f1_score)\n",
    "        \n",
    "        print(f\"\\nRound {round + 1}: Accuracy {accuracy:.4f} - Precision {precision:.4f} - Recall {recall:.4f} - F1-Score {f1_score:.4f}\\n\")\n",
    "\n",
    "        # Cross-node Generalization Calculation\n",
    "        accuracy_variance = np.var(local_accuracies)\n",
    "        accuracy_variances.append(accuracy_variance)\n",
    "        precision_variance = np.var(local_precisions)\n",
    "        precision_variances.append(precision_variance)\n",
    "        recall_variance = np.var(local_recalls)\n",
    "        recall_variances.append(recall_variance)\n",
    "        f1_variance = np.var(local_f1s)\n",
    "        f1_variances.append(f1_variance)\n",
    "\n",
    "        accuracy_std = np.std(local_accuracies)\n",
    "        accuracy_stds.append(accuracy_std)\n",
    "        precision_std = np.std(local_precisions)\n",
    "        precision_stds.append(precision_std)\n",
    "        recall_std = np.std(local_recalls)\n",
    "        recall_stds.append(recall_std)\n",
    "        f1_std = np.std(local_f1s)\n",
    "        f1_stds.append(f1_std)\n",
    "\n",
    "        print(f\"Cross-node Generalization after Round {round + 1}:\")\n",
    "        print(f\"Accuracy Variance: {accuracy_variance:.4f}, Accuracy Std: {accuracy_std:.4f}\")\n",
    "        print(f\"Precision Variance: {precision_variance:.4f}, Precision Std: {precision_std:.4f}\")\n",
    "        print(f\"Recall Variance: {recall_variance:.4f}, Recall Std: {recall_std:.4f}\")\n",
    "        print(f\"F1-Score Variance: {f1_variance:.4f}, F1-Score Std: {f1_std:.4f}\\n\")\n",
    "\n",
    "        # Calculate total training time for the round\n",
    "        total_training_time = sum(local_training_times) + aggregation_time\n",
    "        total_training_times.append(total_training_time)\n",
    "\n",
    "        print(f\"\\nTotal Training Time Round {round + 1}: {total_training_time:.4f}\")\n",
    "\n",
    "        # Calculate total prediction time for the round\n",
    "        total_prediction_time = sum(local_prediction_times)\n",
    "        total_prediction_times.append(total_prediction_time)\n",
    "\n",
    "        print(f\"\\nTotal Prediction Time Round {round + 1}: {total_prediction_time:.4f}\")\n",
    "\n",
    "        # Append round-level resource utilization\n",
    "        cpu_usages.append(np.mean(round_cpu_usage))\n",
    "        memory_usages.append(np.mean(round_memory_usage))\n",
    "\n",
    "    return global_model, global_accuracies, global_precisions, global_recalls, global_f1s, communication_overhead, total_training_times, total_prediction_times, global_pred_times, cpu_usages, memory_usages, accuracy_variances, precision_variances, recall_variances, f1_variances, accuracy_stds, precision_stds, recall_stds, f1_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f8882",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Run the simulation, then get the global model and perfromance metric in each round.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CIDS simulator with Non-IID data from single dataset\n",
    "print(\"Simulation for CIDS with Non-IID Data\\n\")\n",
    "fl_model, fl_global_accuracies, fl_global_precisions, fl_global_recalls, fl_global_f1s, communication_overhead, total_training_times, total_prediction_times, global_pred_times, cpu_usages, memory_usages, accuracy_variances, precision_variances, recall_variances, f1_variances, accuracy_stds, precision_stds, recall_stds, f1_stds = cids_federated_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b721286-d1e5-44f5-a407-790850825bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFinal Communication Overhead: {communication_overhead / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd3d7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Plot the performance metric in each round using graph\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25915d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model performance results\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds1 = np.arange(1, len(fl_global_accuracies) + 1)\n",
    "plt.plot(rounds1, fl_global_accuracies, label='Accuracy')\n",
    "plt.plot(rounds1, fl_global_precisions, label='Precision')\n",
    "plt.plot(rounds1, fl_global_recalls, label='Recall')\n",
    "plt.plot(rounds1, fl_global_f1s, label='F1-Score')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Value')\n",
    "plt.title('CIDS Non-IID FL Model Performance')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107cc8c-e827-4d38-bc6d-3f7e982e949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model robustness and generalization results\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds2 = np.arange(1, len(accuracy_variances) + 1)\n",
    "plt.plot(rounds2, accuracy_variances, label='Accuracy')\n",
    "plt.plot(rounds2, precision_variances, label='Precision')\n",
    "plt.plot(rounds2, recall_variances, label='Recall')\n",
    "plt.plot(rounds2, f1_variances, label='F1-Score')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Value')\n",
    "plt.title('CIDS Non-IID FL Variance in Model Performance Across Nodes')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a1264-9b43-4203-bf9e-dc2f6d5bb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model robustness and generalization results\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds3 = np.arange(1, len(accuracy_stds) + 1)\n",
    "plt.plot(rounds3, accuracy_stds, label='Accuracy')\n",
    "plt.plot(rounds3, precision_stds, label='Precision')\n",
    "plt.plot(rounds3, recall_stds, label='Recall')\n",
    "plt.plot(rounds3, f1_stds, label='F1-Score')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Value')\n",
    "plt.title('CIDS Non-IID FL Standard Deviation of Model Performance')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50612748-1ae3-4895-85cc-f54a2142b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training and prediction time\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds4 = np.arange(1, len(total_training_times) + 1)\n",
    "plt.plot(rounds4, total_training_times, label='Training Time')\n",
    "plt.plot(rounds4, total_prediction_times, label='Prediction Time')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Value')\n",
    "plt.title('CIDS Non-IID FL Training and Prediction Time in Each Round')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2a0da-ace9-497b-a0ce-3073f5be5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting resource consumption\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds5 = np.arange(1, len(cpu_usages) + 1)\n",
    "plt.plot(rounds5, cpu_usages, label='CPU')\n",
    "plt.plot(rounds5, memory_usages, label='RAM')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Value')\n",
    "plt.title('CIDS Non-IID FL Resource Consumption')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb46f7-a4e5-47cd-b1bd-b2aaf02c0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting global prediction time\n",
    "plt.figure(figsize=(28, 20))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "rounds6 = np.arange(1, len(global_pred_times) + 1)\n",
    "plt.plot(rounds6, global_pred_times, label='Glob Pred Time')\n",
    "plt.ylabel('Round')\n",
    "plt.xlabel('Value')\n",
    "plt.title('CIDS Non-IID FL Global Prediction Time')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff5cb9-55c0-4490-81f7-5e187678d30d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Save the performance metric in each round in CSV file\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b19678-1b26-4768-9e81-e68b44e27c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rounds\n",
    "rounds = list(range(1, len(fl_global_accuracies) + 1))\n",
    "\n",
    "# Save global performance metrics with rounds\n",
    "global_metrics_df = pd.DataFrame({\n",
    "    \"Round\": rounds,\n",
    "    \"Global Accuracy\": fl_global_accuracies,\n",
    "    \"Global Precision\": fl_global_precisions,\n",
    "    \"Global Recall\": fl_global_recalls,\n",
    "    \"Global F1-Score\": fl_global_f1s,\n",
    "    \"Global Prediction Time\": global_pred_times,\n",
    "    \"Total Training Times\": total_training_times,\n",
    "    \"Total Prediction Times\": total_prediction_times,\n",
    "    \"CPU Usage\": cpu_usages,\n",
    "    \"Memory Usage\": memory_usages,\n",
    "    \"Accuracy Variance\": accuracy_variances,\n",
    "    \"Precision Variance\": precision_variances,\n",
    "    \"Recall Variance\": recall_variances,\n",
    "    \"F1 Variance\": f1_variances,\n",
    "    \"Accuracy Std\": accuracy_stds,\n",
    "    \"Precision Std\": precision_stds,\n",
    "    \"Recall Std\": recall_stds,\n",
    "    \"F1 Std\": f1_stds\n",
    "})\n",
    "\n",
    "# Export global metrics to a CSV\n",
    "global_metrics_df.to_csv(\"performance_metrics_CIDS_Non-IID.csv\", index=False)\n",
    "\n",
    "print(\"All metrics exported to CSV files successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
